---
layout: post
title: "exploring citizen-ish data science using Google and Microsoft cloud platforms."
date: 2020-03-01
---

Premise
---
Curious about how math, statistics and machine learning can be applied to datasets, thus this blog entry that describes part of the journey with the Google and Microsoft cloud platforms.
Or
Exploring the data science landscape from a citizen (aka n00b-ish) perspective.

Disclaimer (I am not ..):
- a data scientist
- a statistician
- a math major
- claiming any sound knowledge in the technologies discussed here.
This is not yet complete.

Scenario
---
Take a dataset, create a model and predict values.

Dataset
---
HVAC - heating, ventilation, air conditioning  - data describing the time it takes to get a zone of a building to a set temperature in the morning. Dataset includes start, end time and related HVAC metrics.
Goal is to predict how long it will take to get to the required temperature. 
Ideally these predictions could drive when equipment is started to coll   and consequently can we help reduce power consumption.

Assumptions include:
- dataset has been cleaned
- features are identified
	- Setpoint offset at Variable Air Volume system (VAV) start
		- (Room temperature - setpoint for the zone)
	- % Cooling at VAV start
- target is identified: 
	- minutes to cool zone.

Dataset created by [PI Integrator](https://www.osisoft.com/pi-system/pi-capabilities/pi-system-connections/pi-integrators/) with data from [OSIsoft PI System](https://www.osisoft.com/PI-System/) that included raw, calculated and event based (start time, end time) values.

Process
---

Using the provided dataset explore platform options to create predictions

Google
--
[Gaurav's](https://medium.com/@gauravc2708) post on [All things GCP: Machine Learning Deciscion pyramid](https://medium.com/analytics-vidhya/all-things-gcp-machine-learning-decision-pyramid-82260c798a88) provided a map to identify options on GC:

![Google Cloud ML Decision Pyramid](https://miro.medium.com/max/2400/1*Jj3jiMWxYJOMJIcMQj34bw.jpeg)

### BQML

Biq Query Machine Learning enables the use of SQL queries - query example below - to build a model in-database. Observations:
 - nice and simple, with some SQL experience
 - [weights and bias](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-weights) are accessible allowing model deployment externally to BigQuery, e.g.: PI System!

Build the model:

>     SELECT *
>     /* predicted_Event_Frame_Duration_Minute */ 
>     FROM
>     ML.PREDICT(MODEL `introtodatascience.VAVCO_IDENTIFIER.VAVCO_Model`,
>     (  
>     SELECT
>       Event_Frame_Duration_Minute,
>       VAVCO_Startup,
>       Element_Name,
>       Event_Frame_End_Time__Local__TimeStamp,
>       EXTRACT(TIME FROM Event_Frame_End_Time__Local__TimeStamp AT TIME ZONE "America/Los_Angeles") AS End_Time_Only_Pacific_Extract,
>       FORMAT_TIMESTAMP("%T",Event_Frame_End_Time__Local__TimeStamp , "America/Los_Angeles" )AS End_Time_Only_Pacific_Format,
>       Setpoint_Offset_at_start_time,
>       Cooling_Percentage_at_VAV_Start,
>       CASE
>         WHEN Local_Day_of_the_Week = 'Monday' THEN 1
>       ELSE
>       0
>     END
>       AS Is_Monday
>     FROM `introtodatascience.VAVCO_IDENTIFIER.VAVCO_Startups_BigQuery`
>     WHERE
>       Setpoint_reached = "True"
>       /* AND Local_Day_of_the_Week = "Tuesday" */))
Get model coefficients and slope:
> SELECT 
>  * 
> FROM  
>   ML.WEIGHTS(MODEL, `the_model`, STRUCT(true as standardize))

R squared: 0.37

### Auto ML - tables

Imported dataset from Big Query, specified features and target and go! Observations: 

 - easy, point and click
 - the load dataset seemed to take more time than necessary, maybe impatient?
 - multiple [model options](https://cloud.google.com/automl-tables/docs/features) and consequently this takes time
 - Batch, online or export model (Container) options
 - Most likely this option is overkill for the scenario due to processing time and level of hand-holding
 - Not ideal for a lab with limited time (unless resources are spun up beforehand, which takes away from the learning experience).

R squared: 0.582

### Jupyter Notebook

Import dataset from Big Query:

    sql = """
    select * from `hvac-1600.VAV.features`
    """
    df = client.query(sql).to_dataframe()
    df.head()

Notebook away. Observations:
- Clearly knowledge of, or ability to research notebooks, pandas and sklearn required.
- Flexibility
	- spin up various visualizations to explore data
	- get coefficients and bias to deploy on local PI System
- manual everything, not necessarily a bad thing(tm)
- Notebook could be provided for a lab scenario.

R squared: < needs review>

Microsoft
--

Here is a graphic:
![Microsoft ML Algorithm cheat sheet](https://docs.microsoft.com/en-us/azure/machine-learning/media/algorithm-cheat-sheet/machine-learning-algorithm-cheat-sheet.svg)


### Azure Machine Learning Studio (classic)

Loaded data from csv file - since this was available.

[Examples help](https://github.com/microsoft/Reactors/blob/master/Machine_Learning_2/190053-Reactors-DS-Tr2-Sec3-2-Regression2.ipynb)

Observations
- Need to build the data flow, with all drag/drop and enter required parameters
- Easy to change/update/try something else
- Need to "click around" to explore dataset.

R squared: 0.5

----
Possibly to be continued...

